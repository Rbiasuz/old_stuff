{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_endings = r\"[.?!]\"\n",
    "capitalized_words = r\"[A-Z]\\w+\"\n",
    "spaces = r\"\\s+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_one = \"SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!  [clop clop clop] \\nSOLDIER #1: Halt!  Who goes there?\\nARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!\\nSOLDIER #1: Pull the other one!\\nARTHUR: I am, ...  and this is my trusty servant Patsy.  We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.  I must speak with your lord and master.\\nSOLDIER #1: What?  Ridden on a horse?\\nARTHUR: Yes!\\nSOLDIER #1: You're using coconuts!\\nARTHUR: What?\\nSOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\\nARTHUR: So?  We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\\nARTHUR: We found them.\\nSOLDIER #1: Found them?  In Mercea?  The coconut's tropical!\\nARTHUR: What do you mean?\\nSOLDIER #1: Well, this is a temperate zone.\\nARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?\\nSOLDIER #1: Are you suggesting coconuts migrate?\\nARTHUR: Not at all.  They could be carried.\\nSOLDIER #1: What?  A swallow carrying a coconut?\\nARTHUR: It could grip it by the husk!\\nSOLDIER #1: It's not a question of where he grips it!  It's a simple question of weight ratios!  A five ounce bird could not carry a one pound coconut.\\nARTHUR: Well, it doesn't matter.  Will you go and tell your master that Arthur from the Court of Camelot is here.\\nSOLDIER #1: Listen.  In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?\\nARTHUR: Please!\\nSOLDIER #1: Am I right?\\nARTHUR: I'm not interested!\\nSOLDIER #2: It could be carried by an African swallow!\\nSOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.  That's my point.\\nSOLDIER #2: Oh, yeah, I agree with that.\\nARTHUR: Will you ask your master if he wants to join my court at Camelot?!\\nSOLDIER #1: But then of course a-- African swallows are non-migratory.\\nSOLDIER #2: Oh, yeah...\\nSOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!  Supposing two swallows carried it together?\\nSOLDIER #1: No, they'd have to have it on a line.\\nSOLDIER #2: Well, simple!  They'd just use a strand of creeper!\\nSOLDIER #1: What, held under the dorsal guiding feathers?\\nSOLDIER #2: Well, why not?\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SCENE 1: [wind] [clop clop clop] \\nKING ARTHUR: Whoa there!',\n",
       " '[clop clop clop] \\nSOLDIER #1: Halt!',\n",
       " 'Who goes there?',\n",
       " 'ARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.',\n",
       " 'King of the Britons, defeator of the Saxons, sovereign of all England!',\n",
       " 'SOLDIER #1: Pull the other one!',\n",
       " 'ARTHUR: I am, ...  and this is my trusty servant Patsy.',\n",
       " 'We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.',\n",
       " 'I must speak with your lord and master.',\n",
       " 'SOLDIER #1: What?',\n",
       " 'Ridden on a horse?',\n",
       " 'ARTHUR: Yes!',\n",
       " \"SOLDIER #1: You're using coconuts!\",\n",
       " 'ARTHUR: What?',\n",
       " \"SOLDIER #1: You've got two empty halves of coconut and you're bangin' 'em together.\",\n",
       " 'ARTHUR: So?',\n",
       " \"We have ridden since the snows of winter covered this land, through the kingdom of Mercea, through--\\nSOLDIER #1: Where'd you get the coconuts?\",\n",
       " 'ARTHUR: We found them.',\n",
       " 'SOLDIER #1: Found them?',\n",
       " 'In Mercea?',\n",
       " \"The coconut's tropical!\",\n",
       " 'ARTHUR: What do you mean?',\n",
       " 'SOLDIER #1: Well, this is a temperate zone.',\n",
       " 'ARTHUR: The swallow may fly south with the sun or the house martin or the plover may seek warmer climes in winter, yet these are not strangers to our land?',\n",
       " 'SOLDIER #1: Are you suggesting coconuts migrate?',\n",
       " 'ARTHUR: Not at all.',\n",
       " 'They could be carried.',\n",
       " 'SOLDIER #1: What?',\n",
       " 'A swallow carrying a coconut?',\n",
       " 'ARTHUR: It could grip it by the husk!',\n",
       " \"SOLDIER #1: It's not a question of where he grips it!\",\n",
       " \"It's a simple question of weight ratios!\",\n",
       " 'A five ounce bird could not carry a one pound coconut.',\n",
       " \"ARTHUR: Well, it doesn't matter.\",\n",
       " 'Will you go and tell your master that Arthur from the Court of Camelot is here.',\n",
       " 'SOLDIER #1: Listen.',\n",
       " 'In order to maintain air-speed velocity, a swallow needs to beat its wings forty-three times every second, right?',\n",
       " 'ARTHUR: Please!',\n",
       " 'SOLDIER #1: Am I right?',\n",
       " \"ARTHUR: I'm not interested!\",\n",
       " 'SOLDIER #2: It could be carried by an African swallow!',\n",
       " 'SOLDIER #1: Oh, yeah, an African swallow maybe, but not a European swallow.',\n",
       " \"That's my point.\",\n",
       " 'SOLDIER #2: Oh, yeah, I agree with that.',\n",
       " 'ARTHUR: Will you ask your master if he wants to join my court at Camelot?!',\n",
       " 'SOLDIER #1: But then of course a-- African swallows are non-migratory.',\n",
       " 'SOLDIER #2: Oh, yeah...',\n",
       " \"SOLDIER #1: So they couldn't bring a coconut back anyway...  [clop clop clop] \\nSOLDIER #2: Wait a minute!\",\n",
       " 'Supposing two swallows carried it together?',\n",
       " \"SOLDIER #1: No, they'd have to have it on a line.\",\n",
       " 'SOLDIER #2: Well, simple!',\n",
       " \"They'd just use a strand of creeper!\",\n",
       " 'SOLDIER #1: What, held under the dorsal guiding feathers?',\n",
       " 'SOLDIER #2: Well, why not?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Split scene_one into sentences: sentences\n",
    "sentences = sent_tokenize(scene_one)\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARTHUR',\n",
       " ':',\n",
       " 'It',\n",
       " 'is',\n",
       " 'I',\n",
       " ',',\n",
       " 'Arthur',\n",
       " ',',\n",
       " 'son',\n",
       " 'of',\n",
       " 'Uther',\n",
       " 'Pendragon',\n",
       " ',',\n",
       " 'from',\n",
       " 'the',\n",
       " 'castle',\n",
       " 'of',\n",
       " 'Camelot',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use word_tokenize to tokenize the fourth sentence: tokenized_sent\n",
    "tokenized_sent = word_tokenize(sentences[3])\n",
    "\n",
    "tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '#',\n",
       " \"'\",\n",
       " \"'d\",\n",
       " \"'em\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " ',',\n",
       " '--',\n",
       " '.',\n",
       " '...',\n",
       " '1',\n",
       " '2',\n",
       " ':',\n",
       " '?',\n",
       " 'A',\n",
       " 'ARTHUR',\n",
       " 'African',\n",
       " 'Am',\n",
       " 'Are',\n",
       " 'Arthur',\n",
       " 'Britons',\n",
       " 'But',\n",
       " 'Camelot',\n",
       " 'Court',\n",
       " 'England',\n",
       " 'European',\n",
       " 'Found',\n",
       " 'Halt',\n",
       " 'I',\n",
       " 'In',\n",
       " 'It',\n",
       " 'KING',\n",
       " 'King',\n",
       " 'Listen',\n",
       " 'Mercea',\n",
       " 'No',\n",
       " 'Not',\n",
       " 'Oh',\n",
       " 'Patsy',\n",
       " 'Pendragon',\n",
       " 'Please',\n",
       " 'Pull',\n",
       " 'Ridden',\n",
       " 'SCENE',\n",
       " 'SOLDIER',\n",
       " 'Saxons',\n",
       " 'So',\n",
       " 'Supposing',\n",
       " 'That',\n",
       " 'The',\n",
       " 'They',\n",
       " 'Uther',\n",
       " 'Wait',\n",
       " 'We',\n",
       " 'Well',\n",
       " 'What',\n",
       " 'Where',\n",
       " 'Who',\n",
       " 'Whoa',\n",
       " 'Will',\n",
       " 'Yes',\n",
       " 'You',\n",
       " '[',\n",
       " ']',\n",
       " 'a',\n",
       " 'agree',\n",
       " 'air-speed',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'anyway',\n",
       " 'are',\n",
       " 'ask',\n",
       " 'at',\n",
       " 'back',\n",
       " 'bangin',\n",
       " 'be',\n",
       " 'beat',\n",
       " 'bird',\n",
       " 'breadth',\n",
       " 'bring',\n",
       " 'but',\n",
       " 'by',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'carrying',\n",
       " 'castle',\n",
       " 'climes',\n",
       " 'clop',\n",
       " 'coconut',\n",
       " 'coconuts',\n",
       " 'could',\n",
       " 'course',\n",
       " 'court',\n",
       " 'covered',\n",
       " 'creeper',\n",
       " 'defeator',\n",
       " 'do',\n",
       " 'does',\n",
       " 'dorsal',\n",
       " 'empty',\n",
       " 'every',\n",
       " 'feathers',\n",
       " 'five',\n",
       " 'fly',\n",
       " 'forty-three',\n",
       " 'found',\n",
       " 'from',\n",
       " 'get',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'got',\n",
       " 'grip',\n",
       " 'grips',\n",
       " 'guiding',\n",
       " 'halves',\n",
       " 'have',\n",
       " 'he',\n",
       " 'held',\n",
       " 'here',\n",
       " 'horse',\n",
       " 'house',\n",
       " 'husk',\n",
       " 'if',\n",
       " 'in',\n",
       " 'interested',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'join',\n",
       " 'just',\n",
       " 'kingdom',\n",
       " 'knights',\n",
       " 'land',\n",
       " 'length',\n",
       " 'line',\n",
       " 'lord',\n",
       " 'maintain',\n",
       " 'martin',\n",
       " 'master',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'migrate',\n",
       " 'minute',\n",
       " 'must',\n",
       " 'my',\n",
       " \"n't\",\n",
       " 'needs',\n",
       " 'non-migratory',\n",
       " 'not',\n",
       " 'of',\n",
       " 'on',\n",
       " 'one',\n",
       " 'or',\n",
       " 'order',\n",
       " 'other',\n",
       " 'ounce',\n",
       " 'our',\n",
       " 'plover',\n",
       " 'point',\n",
       " 'pound',\n",
       " 'question',\n",
       " 'ratios',\n",
       " 'ridden',\n",
       " 'right',\n",
       " 'search',\n",
       " 'second',\n",
       " 'seek',\n",
       " 'servant',\n",
       " 'simple',\n",
       " 'since',\n",
       " 'snows',\n",
       " 'son',\n",
       " 'south',\n",
       " 'sovereign',\n",
       " 'speak',\n",
       " 'strand',\n",
       " 'strangers',\n",
       " 'suggesting',\n",
       " 'sun',\n",
       " 'swallow',\n",
       " 'swallows',\n",
       " 'tell',\n",
       " 'temperate',\n",
       " 'that',\n",
       " 'the',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'through',\n",
       " 'times',\n",
       " 'to',\n",
       " 'together',\n",
       " 'tropical',\n",
       " 'trusty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'use',\n",
       " 'using',\n",
       " 'velocity',\n",
       " 'wants',\n",
       " 'warmer',\n",
       " 'weight',\n",
       " 'where',\n",
       " 'who',\n",
       " 'why',\n",
       " 'will',\n",
       " 'wind',\n",
       " 'wings',\n",
       " 'winter',\n",
       " 'with',\n",
       " 'yeah',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'zone'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of unique tokens in the entire scene: unique_tokens\n",
    "unique_tokens = set(word_tokenize(scene_one))\n",
    "unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580 588\n"
     ]
    }
   ],
   "source": [
    "# Search for the first occurrence of \"coconuts\" in scene_one: match\n",
    "match = re.search(\"coconuts\", scene_one)\n",
    "\n",
    "# Print the start and end indexes of match\n",
    "print(match.start(), match.end())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(9, 32), match='[wind] [clop clop clop]'>\n"
     ]
    }
   ],
   "source": [
    "# Write a regular expression to search for anything in square brackets: pattern1\n",
    "pattern1 = r\"\\[.*\\]\"\n",
    "\n",
    "# Use re.search to find the first text in square brackets\n",
    "print(re.search(pattern1, scene_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 7), match='ARTHUR:'>\n"
     ]
    }
   ],
   "source": [
    "# Find the script notation at the beginning of the fourth sentence and print it\n",
    "pattern2 = r\"[\\w\\s]+:\"\n",
    "print(re.match(pattern2, sentences[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = ['This is the best #nlp exercise ive found online! #python',\n",
    " '#NLP is super fun! <3 #learning',\n",
    " 'Thanks @datacamp :) #nlp #python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#nlp', '#python']\n"
     ]
    }
   ],
   "source": [
    "# Define a regex pattern to find hashtags: pattern1\n",
    "pattern1 = r\"#\\w+\"\n",
    "# Use the pattern on the first tweet in the tweets list\n",
    "hashtags = regexp_tokenize(tweets[0], pattern1)\n",
    "print(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@datacamp', '#nlp', '#python']\n"
     ]
    }
   ],
   "source": [
    "# Write a pattern that matches both mentions (@) and hashtags\n",
    "pattern2 = r\"([@#]\\w+)\"\n",
    "# Use the pattern on the last tweet in the tweets list\n",
    "mentions_hashtags = regexp_tokenize(tweets[-1], pattern2)\n",
    "print(mentions_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['This', 'is', 'the', 'best', '#nlp', 'exercise', 'ive', 'found', 'online', '!', '#python'], ['#NLP', 'is', 'super', 'fun', '!', '<3', '#learning'], ['Thanks', '@datacamp', ':)', '#nlp', '#python']]\n"
     ]
    }
   ],
   "source": [
    "# Use the TweetTokenizer to tokenize all tweets into one list\n",
    "tknzr = TweetTokenizer()\n",
    "all_tokens = [tknzr.tokenize(t) for t in tweets]\n",
    "print(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_text = 'Wann gehen wir Pizza essen? ðŸ• Und fÃ¤hrst du mit Ãœber? ðŸš•'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wann', 'gehen', 'wir', 'Pizza', 'essen', '?', 'ðŸ•', 'Und', 'fÃ¤hrst', 'du', 'mit', 'Ãœber', '?', 'ðŸš•']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and print all words in german_text\n",
    "all_words = word_tokenize(german_text)\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wann', 'Pizza', 'Und', 'Ãœber']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and print only capital words\n",
    "capital_words = r\"[A-ZÃœ]\\w+\"\n",
    "print(regexp_tokenize(german_text, capital_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ðŸ•', 'ðŸš•']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and print only emoji\n",
    "emoji = \"['\\U0001F300-\\U0001F5FF'|'\\U0001F600-\\U0001F64F'|'\\U0001F680-\\U0001F6FF'|'\\u2600-\\u26FF\\u2700-\\u27BF']\"\n",
    "print(regexp_tokenize(german_text, emoji))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split the script into lines: lines\n",
    "lines = sentences\n",
    "\n",
    "# Replace all script lines for speaker\n",
    "pattern = \"[A-Z]{2,}(\\s)?(#\\d)?([A-Z]{2,})?:\"\n",
    "lines = [re.sub(pattern, '', l) for l in lines]\n",
    "\n",
    "# Tokenize each line: tokenized_lines\n",
    "tokenized_lines = [regexp_tokenize(s, \"\\w+\") for s in lines]\n",
    "\n",
    "# Make a frequency list of lengths: line_num_words\n",
    "line_num_words = [len(t_line) for t_line in tokenized_lines]\n",
    "\n",
    "# Plot a histogram of the line lengths\n",
    "plt.hist(line_num_words)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
